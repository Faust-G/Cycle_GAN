{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN(night_day).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a1500f86a0a46499332cdb6f628283e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d91a3c737e84f1f98b6f778051a74f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dcf789d5205e4d71a5ec125d56510c02",
              "IPY_MODEL_e7efa974c18b497fb560e980d027f9a4",
              "IPY_MODEL_e780ea6243f742b28b074220ab156456"
            ]
          }
        },
        "0d91a3c737e84f1f98b6f778051a74f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcf789d5205e4d71a5ec125d56510c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66e3c6a4f9004bd1b7f8bd8d3f87d28b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "train iter::   1%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be5819dd96a44501b1e7f6face299581"
          }
        },
        "e7efa974c18b497fb560e980d027f9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b94d839ada84963bf1f8aff0614d507",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2228,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_190d8cd0f25a4eb790005a4221212297"
          }
        },
        "e780ea6243f742b28b074220ab156456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9202ebe8b8a47cb8f21ce4603a8a82d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/2228 [00:57&lt;2:53:57,  4.71s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_236a3a635e9d4b799736dd4c405766f6"
          }
        },
        "66e3c6a4f9004bd1b7f8bd8d3f87d28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be5819dd96a44501b1e7f6face299581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b94d839ada84963bf1f8aff0614d507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "190d8cd0f25a4eb790005a4221212297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9202ebe8b8a47cb8f21ce4603a8a82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "236a3a635e9d4b799736dd4c405766f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqQLthKGhCFf"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/night2day.tar.gz\n",
        "!tar -xvf night2day.tar.gz"
      ],
      "metadata": {
        "id": "XNSKql0rrSBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_list = os.listdir('/content/night2day/train/')\n",
        "for i in range(len(dir_list)):\n",
        "  os.rename(f'/content/night2day/train/'+dir_list[i],f'/content/night2day/train/'+str(i)+\".jpg\")\n",
        "dir_list = os.listdir('/content/night2day/test/')\n",
        "for i in range(len(dir_list)):\n",
        "  os.rename(f'/content/night2day/test/'+dir_list[i],f'/content/night2day/test/'+str(i)+\".jpg\")\n",
        "dir_list = os.listdir('/content/night2day/val/')\n",
        "for i in range(len(dir_list)):\n",
        "  os.rename(f'/content/night2day/val/'+dir_list[i],f'/content/night2day/val/'+str(i)+\".jpg\")"
      ],
      "metadata": {
        "id": "rhVK2WEIpb1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class data(Dataset):#transform\n",
        "   def __init__(self, path='/content/night2day/train/'):\n",
        "       self.filenames = glob.glob(path+'*.jpg')\n",
        "      \n",
        "   def __len__(self):\n",
        "       return len(self.filenames)\n",
        "  \n",
        "   def __getitem__(self, idx):\n",
        "       filename = self.filenames[idx]\n",
        "       image = cv2.imread(filename)\n",
        "       image_width = image.shape[1]       \n",
        "       image_width = image_width // 2\n",
        "       real = image[:, :image_width, :]\n",
        "       condition = image[:, image_width:, :]\n",
        "       transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.Resize((256,256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "       ])\n",
        "       real=transform(real)\n",
        "       condition=transform(condition)\n",
        "       return real, condition"
      ],
      "metadata": {
        "id": "oEWaKRTWruZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = data()\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)#transform\n",
        "\n",
        "val_dataset = data(path='/content/night2day/val/')\n",
        "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "BlDU70uRcl4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_loader))[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PzqGxIn-nrj",
        "outputId": "3d14bf49-60e4-4ac6-b1bd-036e720771e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(((torch.permute(next(iter(train_loader))[0][0], (1, 2, 0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8))"
      ],
      "metadata": {
        "id": "IEJbifrK7aXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader={ 'train':train_loader,'validate':val_loader}"
      ],
      "metadata": {
        "id": "3KxnYBJShWTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block_conv(nn.Module):\n",
        "  def __init__(self,inp,out,pool=True,norm=True):\n",
        "    super(Block_conv,self).__init__()\n",
        "    self.conv=nn.Sequential(\n",
        "            nn.Conv2d(inp, out, 3,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2,stride=2) if pool else nn.Identity(),\n",
        "            nn.BatchNorm2d(out) if norm else nn.Identity()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "     return self.conv(x)"
      ],
      "metadata": {
        "id": "AUuRiohlcess"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBc6Qeupit3o",
        "outputId": "e4f7536b-6ddf-46ab-e06d-c1631ed21ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    l=[]\n",
        "    p=3\n",
        "    for i in features:\n",
        "      l.append(Block_conv(p,i))\n",
        "      p=i\n",
        "    self.conv=nn.Sequential(*l)#512*16*16\n",
        "    self.pool=nn.MaxPool2d(16)#512*1*1\n",
        "    self.linear=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.5, inplace=False),\n",
        "        nn.Linear(256,64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(64,16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(16,1),\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=x.to(device)\n",
        "    x=self.conv(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.linear(x)\n",
        "    return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "vGi4wJjzSxN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,features=[64, 128, 256]):\n",
        "        super().__init__()\n",
        "        self.enc_conv0 =nn.Sequential(\n",
        "            Block_conv(3,features[0],False),\n",
        "            Block_conv(features[0],features[0],False,False)\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2,stride=2) \n",
        "        self.upsample =nn.Upsample(scale_factor=2)\n",
        "        self.enc_conv1 = nn.Sequential(\n",
        "            Block_conv(features[0],features[1],False),\n",
        "            Block_conv(features[1],features[1],False,False)\n",
        "        )\n",
        "\n",
        "        self.enc_conv2 =  nn.Sequential(\n",
        "            Block_conv(features[1],features[2],False),\n",
        "            Block_conv(features[2],features[2],False,False)\n",
        "        )\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = nn.Sequential(\n",
        "            nn.Conv2d(features[2], features[2], 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(features[2], features[2], 1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dec_conv0 = nn.Sequential(\n",
        "            Block_conv(features[2]*2,features[2],False),\n",
        "            Block_conv(features[2],features[1],False,False)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dec_conv1 = nn.Sequential(\n",
        "            Block_conv(features[1]*2,features[1],False),\n",
        "            Block_conv(features[1],features[0],False,False)\n",
        "        ) \n",
        "\n",
        "        self.dec_conv2 =nn.Sequential(\n",
        "            Block_conv(features[0]*2,features[0],False),\n",
        "            Block_conv(features[0],3,False,False)\n",
        "        ) \n",
        "\n",
        "  def forward(self, x):\n",
        "        x=x.to(device)\n",
        "        # encoder\n",
        "        e0 =self.enc_conv0(x)\n",
        "        e1 =self.enc_conv1(self.pool(e0))\n",
        "        e2 =self.enc_conv2(self.pool(e1))\n",
        "\n",
        "        # bottleneck\n",
        "        b = self.bottleneck_conv(self.pool(e2))\n",
        "\n",
        "        # decoder\n",
        "        d0 = self.dec_conv0(torch.cat((e2,self.upsample(b)),dim=1))\n",
        "        d1 = self.dec_conv1(torch.cat((e1,self.upsample(d0)),dim=1))\n",
        "        d2 = self.dec_conv2(torch.cat((e0,self.upsample(d1)),dim=1))\n",
        "        return  torch.tanh(d2)"
      ],
      "metadata": {
        "id": "8Vi1sUzl1giq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/val')\n",
        "os.mkdir('/content/val/night')\n",
        "os.mkdir('/content/val/day')"
      ],
      "metadata": {
        "id": "symfNXoB-I7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_scaler = torch.cuda.amp.GradScaler()\n",
        "d_scaler = torch.cuda.amp.GradScaler()\n",
        "L1 = nn.L1Loss()\n",
        "mse = nn.MSELoss()"
      ],
      "metadata": {
        "id": "YRdhCgFXzBgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc_N=Discriminator().to(device)\n",
        "disc_D=Discriminator().to(device)\n",
        "gen_D=Generator().to(device)\n",
        "gen_N=Generator().to(device)"
      ],
      "metadata": {
        "id": "0dtFPtGTDBcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_disc = optim.Adam(\n",
        "        list(disc_N.parameters()) + list(disc_D.parameters()),\n",
        "        lr=1e-4,\n",
        ")\n",
        "opt_gen = optim.Adam(\n",
        "        list(gen_N.parameters()) + list(gen_D.parameters()),\n",
        "        lr=1e-4,\n",
        ")"
      ],
      "metadata": {
        "id": "NO37wf7H5ULB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 7\n",
        "for epoch in range(max_epochs):\n",
        "  for k, dataloader in loader.items():\n",
        "    for night, day in tqdm(dataloader, leave=False, desc=f\"{k} iter:\"):\n",
        "      night=night.to(device)\n",
        "      day=day.to(device)\n",
        "      if k == \"train\":\n",
        "        with torch.cuda.amp.autocast():\n",
        "          fake_night = gen_N(day)\n",
        "          D_N_real = disc_N(night)\n",
        "          D_N_fake = disc_N(fake_night.detach())\n",
        "          D_N_real_loss = mse(D_N_real, torch.ones_like(D_N_real))\n",
        "          D_N_fake_loss = mse(D_N_fake, torch.zeros_like(D_N_fake))\n",
        "          D_N_loss = D_N_real_loss + D_N_fake_loss\n",
        "\n",
        "          fake_day = gen_D(night)\n",
        "          D_D_real = disc_D(day)\n",
        "          D_D_fake = disc_D(fake_day.detach())\n",
        "          D_D_real_loss = mse(D_D_real, torch.ones_like(D_D_real))\n",
        "          D_D_fake_loss = mse(D_D_fake, torch.zeros_like(D_D_fake))\n",
        "          D_D_loss = D_D_real_loss + D_D_fake_loss\n",
        "\n",
        "          D_loss = (D_N_loss + D_D_loss)/2\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(D_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "        with torch.cuda.amp.autocast():\n",
        "          D_D_fake = disc_D(fake_day)\n",
        "          D_N_fake = disc_N(fake_night)\n",
        "          loss_G_D = mse(D_D_fake, torch.ones_like(D_D_fake))\n",
        "          loss_G_N = mse(D_N_fake, torch.ones_like(D_N_fake))\n",
        "\n",
        "          cycle_night = gen_N(fake_day)\n",
        "          cycle_day = gen_D(fake_night)\n",
        "          cycle_night_loss = L1(night, cycle_night)\n",
        "          cycle_day_loss = L1(day, cycle_day)\n",
        "\n",
        "          G_loss = (\n",
        "            loss_G_D\n",
        "            + loss_G_N\n",
        "            + cycle_night_loss * 10\n",
        "            + cycle_day_loss * 10\n",
        "          )\n",
        "          opt_gen.zero_grad()\n",
        "          g_scaler.scale(G_loss).backward()\n",
        "          g_scaler.step(opt_gen)\n",
        "          g_scaler.update()\n",
        "      else:\n",
        "        gen_D.eval() \n",
        "        gen_N.eval()\n",
        "        with torch.no_grad():\n",
        "          with torch.cuda.amp.autocast():\n",
        "            fake_day = ((torch.permute(gen_D(night)[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            fake_night=((torch.permute(gen_N(day)[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            tr_day=((torch.permute(day[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            tr_night=((torch.permute(night[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            Image.fromarray(tr_day).save('/content/val/day/'+'tr'+str(epoch)+'.jpg')\n",
        "            Image.fromarray(tr_night).save('/content/val/night/'+'tr'+str(epoch)+'.jpg')\n",
        "            Image.fromarray(fake_day).save('/content/val/day/'+str(epoch)+'.jpg')\n",
        "            Image.fromarray(fake_night).save('/content/val/night/'+str(epoch)+'.jpg')\n",
        "      day.to('cpu')\n",
        "      night.to('cpu')\n",
        "      torch.cuda.empty_cache()\n",
        "    if k == \"train\":\n",
        "      print(f\"Epoch: {epoch+1}\")\n",
        "    print(f\"Loader: {k}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "2a1500f86a0a46499332cdb6f628283e",
            "0d91a3c737e84f1f98b6f778051a74f7",
            "dcf789d5205e4d71a5ec125d56510c02",
            "e7efa974c18b497fb560e980d027f9a4",
            "e780ea6243f742b28b074220ab156456",
            "66e3c6a4f9004bd1b7f8bd8d3f87d28b",
            "be5819dd96a44501b1e7f6face299581",
            "3b94d839ada84963bf1f8aff0614d507",
            "190d8cd0f25a4eb790005a4221212297",
            "b9202ebe8b8a47cb8f21ce4603a8a82d",
            "236a3a635e9d4b799736dd4c405766f6"
          ]
        },
        "id": "DFmt2UI0FF87",
        "outputId": "c3c989e6-456d-44af-d53c-9b5bed850f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a1500f86a0a46499332cdb6f628283e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "train iter::   0%|          | 0/2228 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-4dcd2eeb3bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mopt_disc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0md_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0md_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_disc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0md_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}