{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN(TPU).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchtext==0.10.0 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "!pip install torch torchvision torchaudio pytorch-lightning\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "T9SYHcwWsfTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/night2day.tar.gz\n",
        "!tar -xvf night2day.tar.gz"
      ],
      "metadata": {
        "id": "FdvgqGNNpOQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import shutil\n",
        "import os\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer"
      ],
      "metadata": {
        "id": "WagWVIKQ2rDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, batch_size=[8,10]):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # download only\n",
        "        dir_list = os.listdir('/content/night2day/train/')\n",
        "        for i in range(len(dir_list)):\n",
        "          os.rename(f'/content/night2day/train/'+dir_list[i],f'/content/night2day/train/'+str(i)+\".jpg\")\n",
        "        dir_list = os.listdir('/content/night2day/test/')\n",
        "        for i in range(len(dir_list)):\n",
        "          os.rename(f'/content/night2day/test/'+dir_list[i],f'/content/night2day/test/'+str(i)+\".jpg\")\n",
        "        dir_list = os.listdir('/content/night2day/val/')\n",
        "        for i in range(len(dir_list)):\n",
        "          os.rename(f'/content/night2day/val/'+dir_list[i],f'/content/night2day/val/'+str(i)+\".jpg\")\n",
        "\n",
        "    def setup(self):\n",
        "      class data(Dataset):#transform\n",
        "        def __init__(self, path='/content/night2day/train/'):\n",
        "          self.filenames = glob.glob(path+'*.jpg')\n",
        "      \n",
        "        def __len__(self):\n",
        "          return len(self.filenames)\n",
        "  \n",
        "        def __getitem__(self, idx):\n",
        "          filename = self.filenames[idx]\n",
        "          image = cv2.imread(filename)\n",
        "          image_width = image.shape[1]       \n",
        "          image_width = image_width // 2\n",
        "          real = image[:, :image_width, :]\n",
        "          condition = image[:, image_width:, :]\n",
        "          transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((256,256)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "          ])\n",
        "          real=transform(real)\n",
        "          condition=transform(condition)\n",
        "          return real, condition\n",
        "      self.train_dataset = data()\n",
        "      self.val_dataset = data(path='/content/night2day/val/')\n",
        "      os.mkdir('/content/val')\n",
        "      os.mkdir('/content/val/night')\n",
        "      os.mkdir('/content/val/day')\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=10, shuffle=False) "
      ],
      "metadata": {
        "id": "VpLtz6T3o6sB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block_conv(nn.Module):\n",
        "  def __init__(self,inp,out,pool=True,norm=True):\n",
        "    super(Block_conv,self).__init__()\n",
        "    self.conv=nn.Sequential(\n",
        "            nn.Conv2d(inp, out, 3,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2,stride=2) if pool else nn.Identity(),\n",
        "            nn.BatchNorm2d(out) if norm else nn.Identity()\n",
        "    )\n",
        "  def forward(self,x):\n",
        "     return self.conv(x)"
      ],
      "metadata": {
        "id": "vzywMTTzyVRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,features=[64, 128, 256, 512]):\n",
        "    super().__init__()\n",
        "    l=[]\n",
        "    p=3\n",
        "    for i in features:\n",
        "      l.append(Block_conv(p,i))\n",
        "      p=i\n",
        "    self.conv=nn.Sequential(*l)#512*16*16\n",
        "    self.pool=nn.MaxPool2d(16)#512*1*1\n",
        "    self.linear=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(p=0.5, inplace=False),\n",
        "        nn.Linear(256,64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(64,16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(16,1),\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=self.conv(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.linear(x)\n",
        "    return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "KMC3PtdkyQNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self,features=[64, 128, 256]):\n",
        "        super().__init__()\n",
        "        self.enc_conv0 =nn.Sequential(\n",
        "            Block_conv(3,features[0],False),\n",
        "            Block_conv(features[0],features[0],False,False)\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(2,stride=2)  # 256 -> 128\n",
        "        self.upsample =nn.Upsample(scale_factor=2)\n",
        "        self.enc_conv1 = nn.Sequential(\n",
        "            Block_conv(features[0],features[1],False),\n",
        "            Block_conv(features[1],features[1],False,False)\n",
        "        )\n",
        "        # self.pool1 =  # 128 -> 64\n",
        "        self.enc_conv2 =  nn.Sequential(\n",
        "            Block_conv(features[1],features[2],False),\n",
        "            Block_conv(features[2],features[2],False,False)\n",
        "        )\n",
        "        # self.pool2 =  # 64 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = nn.Sequential(\n",
        "            nn.Conv2d(features[2], features[2], 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(features[2], features[2], 1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        # self.upsample0 =  # 16 -> 64\n",
        "        self.dec_conv0 = nn.Sequential(\n",
        "            Block_conv(features[2]*2,features[2],False),\n",
        "            Block_conv(features[2],features[1],False,False)\n",
        "        )\n",
        "        # self.upsample1 =  # 64 -> 128\n",
        "        self.dec_conv1 = nn.Sequential(\n",
        "            Block_conv(features[1]*2,features[1],False),\n",
        "            Block_conv(features[1],features[0],False,False)\n",
        "        ) \n",
        "        # self.upsample2 =   # 128 -> 256\n",
        "        self.dec_conv2 =nn.Sequential(\n",
        "            Block_conv(features[0]*2,features[0],False),\n",
        "            Block_conv(features[0],3,False,False)\n",
        "        ) \n",
        "\n",
        "  def forward(self, x):\n",
        "        # encoder\n",
        "        e0 =self.enc_conv0(x)\n",
        "        e1 =self.enc_conv1(self.pool(e0))\n",
        "        e2 =self.enc_conv2(self.pool(e1))\n",
        "\n",
        "        # bottleneck\n",
        "        b = self.bottleneck_conv(self.pool(e2))\n",
        "\n",
        "        # decoder\n",
        "        d0 = self.dec_conv0(torch.cat((e2,self.upsample(b)),dim=1))\n",
        "        d1 = self.dec_conv1(torch.cat((e1,self.upsample(d0)),dim=1))\n",
        "        d2 = self.dec_conv2(torch.cat((e0,self.upsample(d1)),dim=1))\n",
        "        return  torch.tanh(d2)"
      ],
      "metadata": {
        "id": "QHvU5tcx0pld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(pl.LightningModule):\n",
        "    def __init__(self,disc_N,disc_D,gen_D,gen_N):\n",
        "            super().__init__()\n",
        "            self.disc_N=disc_N\n",
        "            self.disc_D=disc_D\n",
        "            self.gen_D=gen_D\n",
        "            self.gen_N=gen_N\n",
        "            self.L1 = nn.L1Loss()\n",
        "            self.mse = nn.MSELoss()\n",
        "            self.g_loss_glob=1e9\n",
        "            self.automatic_optimization = False\n",
        "  \n",
        "      # Настраиваются параметры обучения\n",
        "    def training_step(self, batch, batch_idx):\n",
        "            x, y = batch\n",
        "            opt_disc, opt_gen=self.optimizers()\n",
        "            night,day=batch\n",
        "            fake_night = self.gen_N(day)\n",
        "            D_N_real = self.disc_N(night)\n",
        "            D_N_fake = self.disc_N(fake_night.detach())\n",
        "            D_N_real_loss = self.mse(D_N_real, torch.ones_like(D_N_real))\n",
        "            D_N_fake_loss = self.mse(D_N_fake, torch.zeros_like(D_N_fake))\n",
        "            D_N_loss = D_N_real_loss + D_N_fake_loss\n",
        "\n",
        "            fake_day = self.gen_D(night)\n",
        "            D_D_real = self.disc_D(day)\n",
        "            D_D_fake = self.disc_D(fake_day.detach())\n",
        "            D_D_real_loss = self.mse(D_D_real, torch.ones_like(D_D_real))\n",
        "            D_D_fake_loss = self.mse(D_D_fake, torch.zeros_like(D_D_fake))\n",
        "            D_D_loss = D_D_real_loss + D_D_fake_loss\n",
        "            D_loss = (D_N_loss + D_D_loss)/2\n",
        "\n",
        "            opt_disc.zero_grad()\n",
        "            D_loss.backward()\n",
        "            opt_disc.step()\n",
        "\n",
        "            D_D_fake = self.disc_D(fake_day)\n",
        "            D_N_fake = self.disc_N(fake_night)\n",
        "            loss_G_D = self.mse(D_D_fake, torch.ones_like(D_D_fake))\n",
        "            loss_G_N = self.mse(D_N_fake, torch.ones_like(D_N_fake))\n",
        "\n",
        "            cycle_night = self.gen_N(fake_day)\n",
        "            cycle_day = self.gen_D(fake_night)\n",
        "            cycle_night_loss = self.L1(night, cycle_night)\n",
        "            cycle_day_loss = self.L1(day, cycle_day)\n",
        "\n",
        "            G_loss = (\n",
        "              loss_G_D\n",
        "              + loss_G_N\n",
        "              + cycle_night_loss * 10\n",
        "              + cycle_day_loss * 10\n",
        "            )\n",
        "            opt_gen.zero_grad()\n",
        "            G_loss.backward()\n",
        "            opt_gen.step()\n",
        "\n",
        "            return self.log_dict({\"G_loss\": G_loss, \"D_loss\": D_loss}, prog_bar=True)\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "            night,day=batch\n",
        "\n",
        "            fake_night = self.gen_N(day)\n",
        "            fake_day = self.gen_D(night)\n",
        "            \n",
        "            place_n='/content/val/night/'+str(self.current_epoch)\n",
        "            place_d='/content/val/day/'+str(self.current_epoch)\n",
        "            try:\n",
        "              os.mkdir(place_n)\n",
        "              os.mkdir(place_d)\n",
        "            except Exception:\n",
        "              pass\n",
        "            # fake_day_np = ((torch.permute(fake_day[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            # fake_night_np=((torch.permute(fake_night[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            # tr_day=((torch.permute(day[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            # tr_night=((torch.permute(night[0],(1,2,0)).to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            # Image.fromarray(tr_day).save(place_d+'/tr.jpg')\n",
        "            # Image.fromarray(tr_night).save(place_n+'/tr.jpg')\n",
        "            # Image.fromarray(fake_day_np).save(place_d+'/l.jpg')\n",
        "            # Image.fromarray(fake_night_np).save(place_n+'/l.jpg')\n",
        "            fake_day_np = ((fake_day.to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            fake_night_np=((fake_night.to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            tr_day=((day.to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            tr_night=((night.to('cpu').numpy()*0.5+0.5)*255).astype(np.uint8)\n",
        "            for i in range(fake_day.shape[0]):\n",
        "              Image.fromarray(tr_day[i].transpose(1,2,0)).save(place_d+'/tr'+str(i)+'.jpg')\n",
        "              Image.fromarray(tr_night[i].transpose(1,2,0)).save(place_n+'/tr'+str(i)+'.jpg')\n",
        "              Image.fromarray(fake_day_np[i].transpose(1,2,0)).save(place_d+'/l'+str(i)+'.jpg')\n",
        "              Image.fromarray(fake_night_np[i].transpose(1,2,0)).save(place_n+'/l'+str(i)+'.jpg')\n",
        "            D_D_fake = self.disc_D(fake_day)\n",
        "            D_N_fake = self.disc_N(fake_night)\n",
        "            loss_G_D = self.mse(D_D_fake, torch.ones_like(D_D_fake))\n",
        "            loss_G_N = self.mse(D_N_fake, torch.ones_like(D_N_fake))\n",
        "            cycle_night = self.gen_N(fake_day)\n",
        "            cycle_day = self.gen_D(fake_night)\n",
        "            cycle_night_loss = self.L1(night, cycle_night)\n",
        "            cycle_day_loss = self.L1(day, cycle_day)\n",
        "\n",
        "            G_loss = (\n",
        "              loss_G_D\n",
        "              + loss_G_N\n",
        "              + cycle_night_loss * 10\n",
        "              + cycle_day_loss * 10\n",
        "            )\n",
        "            if self.g_loss_glob>G_loss:\n",
        "                torch.save(gen_N.state_dict(), \"./gen_N_best.pth\")\n",
        "                torch.save(gen_D.state_dict(), \"./gen_D_best.pth\")\n",
        "                self.g_loss_glob=G_loss\n",
        "            torch.save(gen_N.state_dict(), \"./gen_N.pth\")\n",
        "            torch.save(gen_D.state_dict(), \"./gen_D.pth\")    \n",
        "            return self.log_dict({\"G_loss\": G_loss}, prog_bar=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_gen = torch.optim.Adam(list(self.gen_N.parameters()) + list(self.gen_D.parameters()), lr=1e-4)\n",
        "        opt_disc = torch.optim.Adam(list(self.disc_N.parameters()) + list(self.disc_D.parameters()), lr=1e-4)\n",
        "        return opt_disc, opt_gen"
      ],
      "metadata": {
        "id": "4ll0j783OgE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc_N=Discriminator()\n",
        "disc_D=Discriminator()\n",
        "gen_D=Generator()\n",
        "gen_N=Generator()\n",
        "dm = DataModule()\n",
        "dm.prepare_data()\n",
        "dm.setup()"
      ],
      "metadata": {
        "id": "nO_Xs4bM68sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc_N.load_state_dict(torch.load('/content/gen_N_best.pth'))\n",
        "disc_D.load_state_dict(torch.load('/content/gen_D_best.pth'))"
      ],
      "metadata": {
        "id": "1K-qeLty2g9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=GAN(disc_N,disc_D,gen_D,gen_N)\n",
        "trainer = pl.Trainer(tpu_cores=8, precision=16)\n",
        "trainer.fit(model,dm)"
      ],
      "metadata": {
        "id": "IfEKaMp7R6jH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}